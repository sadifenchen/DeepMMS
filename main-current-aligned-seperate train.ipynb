{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cc44e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning on use of the timeseries module: If the inherent timescales of the system are long compared to those being analyzed, this statistical inefficiency may be an underestimate.  The estimate presumes the use of many statistically independent samples.  Tests should be performed to assess whether this condition is satisfied.   Be cautious in the interpretation of the data.\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from flax import linen as nn\n",
    "from flax.training import train_state\n",
    "from flax.linen.initializers import zeros as nn_zeros\n",
    "import optax\n",
    "import pymbar\n",
    "import sys\n",
    "import jax_amber_tanh_align as jax_amber\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from jax.scipy.stats.multivariate_normal import logpdf\n",
    "\n",
    "import json\n",
    "\n",
    "from flax.linen.initializers import lecun_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a142344",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_kernel_init = lecun_normal()\n",
    "\n",
    "RT = jnp.float32(8.3144621E-3 * 300.0)\n",
    "beta = jnp.float32(1.0)/RT\n",
    "nm2ang = jnp.float32(10.0)\n",
    "ang2nm = jnp.float32(0.1)\n",
    "\n",
    "def get_energy_values(x, ener_funs, R0):\n",
    "    ener_nHO_fun, ener_wHO_fun, ener_bond_fun = ener_funs\n",
    "    enr_bnd = jax.vmap(ener_bond_fun)(x)\n",
    "    enr_nHO = jax.vmap(ener_nHO_fun)(x)\n",
    "    enr_wHO = jax.vmap(ener_wHO_fun, in_axes=(0, None))(x, R0)\n",
    "    return enr_bnd, enr_nHO, enr_wHO\n",
    "\n",
    "def get_trajectory (fname_prmtop, fname_dcd, nsamp):\n",
    "    import mdtraj as md\n",
    "\n",
    "    c = md.load (fname_dcd, top=fname_prmtop)\n",
    "    c = c.superpose(c)\n",
    "    crds = jnp.array (c.xyz)\n",
    "    return crds[-nsamp:], crds[:-nsamp] # in nm unit\n",
    "\n",
    "class AfflineCoupling(nn.Module):\n",
    "    input_size: int\n",
    "    i_dim: int\n",
    "    hidden_layers: int\n",
    "    hidden_dim: int\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, inputs, reverse=False):\n",
    "\n",
    "        fixed_mask = jnp.ones((self.input_size), dtype=jnp.int32).reshape(-1, 3)\n",
    "        fixed_mask = fixed_mask.at[:, self.i_dim].set(0)\n",
    "        moved_mask = jnp.int32(1) - fixed_mask\n",
    "        moved_mask = moved_mask.reshape(1, -1)\n",
    "        fixed_mask = fixed_mask.reshape(1, -1)\n",
    "        y = inputs * fixed_mask\n",
    "\n",
    "        for _ in range(self.hidden_layers):\n",
    "            y = nn.relu(nn.Dense(features=self.hidden_dim, kernel_init=default_kernel_init)(y))\n",
    "            #y = nn.leaky_relu(nn.Dense(features=self.hidden_dim, kernel_init=default_kernel_init)(y))\n",
    "            #y = nn.swish(nn.Dense(features=self.hidden_dim, kernel_init=default_kernel_init)(y))\n",
    "\n",
    "        log_scale = nn.Dense(features=self.input_size, kernel_init=nn_zeros)(y)\n",
    "        shift = nn.Dense(features=self.input_size, kernel_init=nn_zeros)(y)\n",
    "        shift = shift * moved_mask\n",
    "        log_scale = log_scale * moved_mask\n",
    "\n",
    "        if reverse:\n",
    "            log_scale = -log_scale\n",
    "            outputs = (inputs - shift) * jnp.exp(log_scale)\n",
    "        else:\n",
    "            outputs = inputs * jnp.exp(log_scale) + shift\n",
    "\n",
    "        return outputs, log_scale\n",
    "\n",
    "\n",
    "class realNVP3(nn.Module):\n",
    "    input_size: int\n",
    "    hidden_layers: int\n",
    "    hidden_dim: int\n",
    "\n",
    "    def setup(self):\n",
    "\n",
    "        self.af_x = AfflineCoupling(self.input_size, i_dim=0,\n",
    "                                    hidden_layers=self.hidden_layers,\n",
    "                                    hidden_dim=self.hidden_dim)\n",
    "        self.af_y = AfflineCoupling(self.input_size, i_dim=1,\n",
    "                                    hidden_layers=self.hidden_layers,\n",
    "                                    hidden_dim=self.hidden_dim)\n",
    "        self.af_z = AfflineCoupling(self.input_size, i_dim=2,\n",
    "                                    hidden_layers=self.hidden_layers,\n",
    "                                    hidden_dim=self.hidden_dim)\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, inputs, reverse=False):\n",
    "        n_conf, n_atoms, n_dim = inputs.shape\n",
    "\n",
    "        outputs = inputs.reshape(n_conf, -1)\n",
    "        if reverse:\n",
    "            outputs, log_J_z = self.af_z(outputs, reverse)\n",
    "            outputs, log_J_y = self.af_y(outputs, reverse)\n",
    "            outputs, log_J_x = self.af_x(outputs, reverse)\n",
    "        else:\n",
    "            outputs, log_J_x = self.af_x(outputs)\n",
    "            outputs, log_J_y = self.af_y(outputs)\n",
    "            outputs, log_J_z = self.af_z(outputs)\n",
    "\n",
    "        return outputs.reshape(n_conf, n_atoms, n_dim), \\\n",
    "            (log_J_x + log_J_y + log_J_z).sum(axis=-1)\n",
    "\n",
    "    \n",
    "class NNflows(nn.Module):\n",
    "    input_size: int\n",
    "    hidden_layers: int\n",
    "    hidden_dim: int\n",
    "\n",
    "    def setup(self):\n",
    "\n",
    "        self.af_x = AfflineCoupling(self.input_size, i_dim=0,\n",
    "                                    hidden_layers=self.hidden_layers,\n",
    "                                    hidden_dim=self.hidden_dim)\n",
    "        self.af_y = AfflineCoupling(self.input_size, i_dim=1,\n",
    "                                    hidden_layers=self.hidden_layers,\n",
    "                                    hidden_dim=self.hidden_dim)\n",
    "        self.af_z = AfflineCoupling(self.input_size, i_dim=2,\n",
    "                                    hidden_layers=self.hidden_layers,\n",
    "                                    hidden_dim=self.hidden_dim)\n",
    "\n",
    "        self.af_x2 = AfflineCoupling(self.input_size, i_dim=0,\n",
    "                                    hidden_layers=self.hidden_layers,\n",
    "                                    hidden_dim=self.hidden_dim)\n",
    "        self.af_y2 = AfflineCoupling(self.input_size, i_dim=1,\n",
    "                                    hidden_layers=self.hidden_layers,\n",
    "                                    hidden_dim=self.hidden_dim)\n",
    "        self.af_z2 = AfflineCoupling(self.input_size, i_dim=2,\n",
    "                                    hidden_layers=self.hidden_layers,\n",
    "                                    hidden_dim=self.hidden_dim)\n",
    "\n",
    "        self.af_x3 = AfflineCoupling(self.input_size, i_dim=0,\n",
    "                                    hidden_layers=self.hidden_layers,\n",
    "                                    hidden_dim=self.hidden_dim)\n",
    "        self.af_y3 = AfflineCoupling(self.input_size, i_dim=1,\n",
    "                                    hidden_layers=self.hidden_layers,\n",
    "                                    hidden_dim=self.hidden_dim)\n",
    "        self.af_z3 = AfflineCoupling(self.input_size, i_dim=2,\n",
    "                                    hidden_layers=self.hidden_layers,\n",
    "                                    hidden_dim=self.hidden_dim)\n",
    "\n",
    "        #self.blocks = [[self.af_x, self.af_ym self.af_z], [self.af_x2, self.af_y2, self.af_z2], [self.af_x3, self.af_y3, self.af_z3]\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, inputs, reverse=False):\n",
    "        n_conf, n_atoms, n_dim = inputs.shape\n",
    "\n",
    "        outputs = inputs.reshape(n_conf, -1)\n",
    "        if reverse:\n",
    "            outputs, log_J_z3 = self.af_z3(outputs, reverse)\n",
    "            outputs, log_J_y3 = self.af_y3(outputs, reverse)\n",
    "            outputs, log_J_x3 = self.af_x3(outputs, reverse)\n",
    "\n",
    "            outputs, log_J_z2 = self.af_z2(outputs, reverse)\n",
    "            outputs, log_J_y2 = self.af_y2(outputs, reverse)\n",
    "            outputs, log_J_x2 = self.af_x2(outputs, reverse)\n",
    "\n",
    "            outputs, log_J_z = self.af_z(outputs, reverse)\n",
    "            outputs, log_J_y = self.af_y(outputs, reverse)\n",
    "            outputs, log_J_x = self.af_x(outputs, reverse)\n",
    "        else:\n",
    "            outputs, log_J_x = self.af_x(outputs)\n",
    "            outputs, log_J_y = self.af_y(outputs)\n",
    "            outputs, log_J_z = self.af_z(outputs)\n",
    "\n",
    "            outputs, log_J_x2 = self.af_x2(outputs)\n",
    "            outputs, log_J_y2 = self.af_y2(outputs)\n",
    "            outputs, log_J_z2 = self.af_z2(outputs)\n",
    "\n",
    "            outputs, log_J_x3 = self.af_x3(outputs)\n",
    "            outputs, log_J_y3 = self.af_y3(outputs)\n",
    "            outputs, log_J_z3 = self.af_z3(outputs)\n",
    "\n",
    "        return outputs.reshape(n_conf, n_atoms, n_dim), \\\n",
    "            (log_J_x + log_J_y + log_J_z + log_J_x2 + log_J_y2 + log_J_z2 + log_J_x3 + log_J_y3 + log_J_z3).sum(axis=-1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def rmsf(x):\n",
    "    n, m, k = x.shape\n",
    "\n",
    "    # Calculate the average positions over all frames\n",
    "    avg_positions = jnp.mean(x, axis=0)\n",
    "\n",
    "    # Calculate the deviations for each atom at each frame\n",
    "    rmsf = jnp.sqrt(jnp.sum((x - avg_positions[None, :, :])**2)/m)\n",
    "\n",
    "    # Calculate the RMSF for each atom by taking the root mean square of the deviations over all frames\n",
    "\n",
    "\n",
    "    return rmsf\n",
    "\n",
    "\n",
    "def get_gaussian_energy(x, x_A_flat_mean, x_A_flat_cov, factor):\n",
    "    x_flat = x.reshape([x.shape[0], x.shape[1] * x.shape[2]])\n",
    "\n",
    "    enr_gaus = -logpdf(x_flat, x_A_flat_mean, x_A_flat_cov/factor)\n",
    "\n",
    "    return enr_gaus\n",
    "\n",
    "\n",
    "def main_f(x_A, tx_A, R0_A, result = 'A.txt'):\n",
    "    with open('my_results/'+result, 'w') as file:\n",
    "        file.write('start\\n')\n",
    "    \n",
    "    rng = jax.random.PRNGKey(0)\n",
    "    rng, x_key, tx_key = jax.random.split(rng, num=3)\n",
    "\n",
    "    x_A_flat = x_A.reshape([x_A.shape[0], x_A.shape[1] * x_A.shape[2]])\n",
    "    x_A_mean = jnp.mean(x_A, axis=0)\n",
    "    x_A_flat_mean = jnp.mean(x_A_flat, axis=0)\n",
    "    x_A_flat_cov_oring = jnp.cov(x_A_flat, rowvar=False)\n",
    "    x_A_flat_cov = x_A_flat_cov_oring + 0.1 * jnp.diag(x_A_flat_cov_oring).min() * jnp.eye(x_A_flat_cov_oring.shape[0])\n",
    "\n",
    "    fixed_atoms = jnp.array(json_data['fixed']['atoms']) - 1\n",
    "    #R0_A = jnp.array(json_data['fixed']['R0_A'])\n",
    "    kval = jnp.float32(json_data['fixed']['kval'])\n",
    "\n",
    "    nconf = x_A.shape[0]\n",
    "\n",
    "    input_size = x_A.shape[1] * 3\n",
    "    hidden_dim = json_data['realNVP']['hidden_dim']\n",
    "    hidden_layers = json_data['realNVP']['hidden_layers']\n",
    "\n",
    "    model = NNflows(input_size=input_size,\n",
    "                     hidden_layers=hidden_layers,\n",
    "                     hidden_dim=hidden_dim)\n",
    "    ener_funs = jax_amber.get_amber_energy_funs(json_data['fname_prmtop'],\n",
    "                                                fixed_atoms[-1],\n",
    "                                                kval)\n",
    "    _, ener_wHO_fun, ener_bond_fun = ener_funs\n",
    "\n",
    "    _, enr_bnd_A0, enr_wHO_A0 = get_energy_values(x_A, ener_funs, R0_A)\n",
    "\n",
    "    _, tenr_bnd_A0, tenr_wHO_A0 = get_energy_values(tx_A, ener_funs, R0_A)\n",
    "\n",
    "    lr = json_data['optax']['learning_rate']\n",
    "    total_steps = json_data['optax']['total_steps']\n",
    "    alpha = json_data['optax']['alpha']\n",
    "    scheduler = optax.cosine_decay_schedule(lr,\n",
    "                                            decay_steps=total_steps,\n",
    "                                            alpha=alpha)\n",
    "\n",
    "    opt_method = optax.chain(\n",
    "        optax.clip(1.0),\n",
    "        optax.adam(learning_rate=scheduler)\n",
    "    )\n",
    "\n",
    "    state = train_state.TrainState.create(\n",
    "        apply_fn=model.apply,\n",
    "        params=model.init(rng, x_A)['params'],\n",
    "        tx=opt_method\n",
    "    )\n",
    "\n",
    "    fixed_R0 = (R0_A)\n",
    "\n",
    "    loss_hist = []\n",
    "    loss_oring_hist = []\n",
    "    loss_oring_f_hist = []\n",
    "    loss_f_hist = []\n",
    "    loss_b_hist = []\n",
    "    loss_oring_b_hist = []\n",
    "\n",
    "    tm_A_hist = []\n",
    "    m_A_hist = []\n",
    "    tm_B_hist = []\n",
    "\n",
    "    switch_gear = []\n",
    "    iterations = 0\n",
    "\n",
    "    state_hist_full = []\n",
    "\n",
    "    for multip in jnp.arange(30):\n",
    "        switch_gear.append(iterations)\n",
    "\n",
    "        factor = 5 * (0.9 ** multip)\n",
    "        \n",
    "        #factor = 1\n",
    "        # if multip == 8:\n",
    "        # factor = 1\n",
    "\n",
    "        #if multip == 11:\n",
    "            #factor = 1\n",
    "        # factor = 1\n",
    "\n",
    "        print(factor)\n",
    "\n",
    "        x_B_flat = jax.random.multivariate_normal(x_key, x_A_flat_mean, x_A_flat_cov / factor, (x_A.shape[0],),\n",
    "                                                  method='svd')\n",
    "        tx_B_flat = jax.random.multivariate_normal(tx_key, x_A_flat_mean, x_A_flat_cov / factor, (tx_A.shape[0],),\n",
    "                                                   method='svd')\n",
    "        # x_B_flat = jax.random.multivariate_normal(x_key, x_A_flat_mean, jnp.eye(x_A_flat_mean.shape[0]) / factor, [x_A.shape[0]])\n",
    "        # tx_B_flat = jax.random.multivariate_normal(tx_key, x_A_flat_mean, jnp.eye(x_A_flat_mean.shape[0]) / factor, [x_A.shape[0]])\n",
    "\n",
    "        x_B = x_B_flat.reshape(x_A.shape)\n",
    "        tx_B = tx_B_flat.reshape(tx_A.shape)\n",
    "\n",
    "        def get_gaussian_energy(x):\n",
    "            x_flat = x.reshape([x.shape[0], x.shape[1] * x.shape[2]])\n",
    "\n",
    "            enr_gaus = -logpdf(x_flat, x_A_flat_mean, x_A_flat_cov / factor)\n",
    "\n",
    "            return enr_gaus\n",
    "\n",
    "        enr_B0 = get_gaussian_energy(x_B)\n",
    "        tenr_B0 = get_gaussian_energy(tx_B)\n",
    "\n",
    "        ener_ref0 = \\\n",
    "            (enr_wHO_A0, enr_B0, enr_bnd_A0)\n",
    "\n",
    "        tener_ref0 = \\\n",
    "            (tenr_wHO_A0, tenr_B0, tenr_bnd_A0)\n",
    "\n",
    "        def loss_value(ener_wHO_fn, ener_bond_fn, enr0_wHO, m_B, log_J_F, m_A, log_J_R, fixed_R0):\n",
    "            enr_wHO_A0, enr_B0, _ = enr0_wHO\n",
    "            R0_A = fixed_R0\n",
    "\n",
    "            enr_A = jax.vmap(ener_wHO_fn, in_axes=(0, None))(m_A, R0_A)\n",
    "\n",
    "            # m_B_flat = m_B.reshape([m_B.shape[0], m_B.shape[1] * m_B.shape[2]])\n",
    "            # enr_B = logpdf(m_B_flat, mean=mean, cov=cov)\n",
    "            enr_B = get_gaussian_energy(m_B)\n",
    "\n",
    "            # enr_bnd_A = jax.vmap(ener_bond_fn) (m_A)\n",
    "\n",
    "            loss_F = beta * (enr_B - enr_wHO_A0) - log_J_F\n",
    "            loss_R = beta * (enr_A - enr_B0) - log_J_R\n",
    "\n",
    "            loss = loss_F.mean() + loss_R.mean()\n",
    "\n",
    "            return loss, loss_F, loss_R\n",
    "\n",
    "        @jax.jit\n",
    "        def train_step(state, inputs, ener_wHO_ref0, fixed_R0):\n",
    "            def loss_fn(params, apply_fn):\n",
    "                x_A, x_B = inputs\n",
    "\n",
    "                m_B, log_J_F = apply_fn({'params': params}, x_A)\n",
    "                m_A, log_J_R = apply_fn({'params': params}, x_B, reverse=True)\n",
    "\n",
    "                loss, loss_f, loss_b = loss_value(ener_wHO_fun, ener_bond_fun, ener_wHO_ref0,\n",
    "                                        m_B, log_J_F, m_A, log_J_R, fixed_R0)\n",
    "\n",
    "                return loss_f.mean()\n",
    "\n",
    "            grads = jax.grad(loss_fn)(state.params, state.apply_fn)\n",
    "\n",
    "            return state.apply_gradients(grads=grads)\n",
    "\n",
    "        state_hist = []\n",
    "        for epoch in range(50000):\n",
    "\n",
    "            iterations += 1\n",
    "            # for ist0 in range(0, nconf, 200):\n",
    "            #    ied0 = ist0 + 200\n",
    "            #    ied0 = jnp.where(ied0 < nconf, ied0, nconf)\n",
    "            #    batch = (x_A[ist0:ied0], x_B[ist0:ied0])\n",
    "            #    ener_wHO_ref0 = (enr_wHO_A0[ist0:ied0], enr_B0[ist0:ied0],\n",
    "            #                     enr_bnd_A0)\n",
    "\n",
    "            #    state = train_step(state, batch, ener_wHO_ref0, fixed_R0)\n",
    "            #rng, x_key= jax.random.split(rng, num=2)\n",
    "            #choice = jax.random.choice(x_key, 8000, shape = [500])\n",
    "            #batch = (x_A[choice], x_B[choice])\n",
    "            \n",
    "            #ener_wHO_ref0 = (enr_wHO_A0[choice], enr_B0[choice],\n",
    "            #                     enr_bnd_A0)\n",
    "            batch = (x_A, x_B)\n",
    "            ener_wHO_ref0 = (enr_wHO_A0, enr_B0, enr_bnd_A0)\n",
    "            state = train_step(state, batch, ener_wHO_ref0, fixed_R0)\n",
    "\n",
    "            if (epoch) % 500 == 0:\n",
    "                #state_hist.append(state.params)\n",
    "\n",
    "                tm_B, tlog_J_F = state.apply_fn({'params': state.params}, tx_A)\n",
    "\n",
    "                tm_A, tlog_J_R = state.apply_fn({'params': state.params}, tx_B, reverse=True)\n",
    "\n",
    "                loss, loss_f, loss_b = loss_value(ener_wHO_fun, ener_bond_fun, tener_ref0,\n",
    "                                                  tm_B, tlog_J_F, tm_A, tlog_J_R, fixed_R0)\n",
    "                \n",
    "\n",
    "                loss_hist.append(loss.item())\n",
    "                loss_f_hist.append(loss_f.mean().item())\n",
    "                loss_b_hist.append(loss_b.mean().item())\n",
    "                \n",
    "                with open('my_results/'+result, 'a') as file:\n",
    "                    file.write('factor: ' + str(factor) + ' epoch: '+ str(epoch) + '\\n loss: ' + str(loss) + '\\n')\n",
    "                    file.write('forward: '+ str(loss_f.mean()) + ' backward: ' + str(loss_b.mean()) + '\\n')\n",
    "\n",
    "                m_B, log_J_F = state.apply_fn({'params': state.params}, x_A)\n",
    "\n",
    "                m_A, log_J_R = state.apply_fn({'params': state.params}, x_B, reverse=True)\n",
    "                \n",
    "                if epoch>2000:\n",
    "                \n",
    "                    last5 = loss_hist[-5:-1]\n",
    "                    last5_2 = loss_hist[-4:]\n",
    "\n",
    "                    last5_b = loss_b_hist[-5:-1]\n",
    "                    last5_b_2 = loss_b_hist[-4:]\n",
    "                    \n",
    "                    last5_f = loss_f_hist[-5:-1]\n",
    "                    last5_f_2 = loss_f_hist[-4:]\n",
    "                    \n",
    "                    if loss_hist[-1] >= 10000:\n",
    "                        state = state.replace (params=test_ckpt['params'],opt_state=test_ckpt['opt_state'])\n",
    "\n",
    "                        break\n",
    "                        \n",
    "                    if loss_f_hist[-1] >= 10000:\n",
    "                        state = state.replace (params=test_ckpt['params'],opt_state=test_ckpt['opt_state'])\n",
    "                        break\n",
    "                        \n",
    "                    if loss_b_hist[-1] >= 10000:\n",
    "                        state = state.replace (params=test_ckpt['params'],opt_state=test_ckpt['opt_state'])\n",
    "                        break\n",
    "\n",
    "                    if (np.mean(last5_f) + 2*np.abs(np.mean(last5_f))) <= np.mean(last5_f_2):\n",
    "\n",
    "                        break\n",
    "\n",
    "                    if epoch > 4000:\n",
    "\n",
    "                        if np.mean(last5) <= np.mean(last5_2):\n",
    "                            if np.mean(last5_b) <= np.mean(last5_b_2):\n",
    "                                break\n",
    "                                \n",
    "                test_ckpt = {'params': state.params, \n",
    "                            'opt_state':state.opt_state}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                        \n",
    "                #if epoch%1000 == 0:\n",
    "                    #print(epoch, loss)\n",
    "        state_hist.append(state.params)\n",
    "        state_hist_full.append(state_hist)\n",
    "\n",
    "\n",
    "    return state_hist_full, [x_A_flat_mean, x_A_flat_cov]\n",
    "\n",
    "def main_b(x_A, tx_A, R0_A, result = 'A.txt'):\n",
    "    with open('my_results/'+result, 'w') as file:\n",
    "        file.write('start\\n')\n",
    "    \n",
    "    rng = jax.random.PRNGKey(0)\n",
    "    rng, x_key, tx_key = jax.random.split(rng, num=3)\n",
    "\n",
    "    x_A_flat = x_A.reshape([x_A.shape[0], x_A.shape[1] * x_A.shape[2]])\n",
    "    x_A_mean = jnp.mean(x_A, axis=0)\n",
    "    x_A_flat_mean = jnp.mean(x_A_flat, axis=0)\n",
    "    x_A_flat_cov_oring = jnp.cov(x_A_flat, rowvar=False)\n",
    "    x_A_flat_cov = x_A_flat_cov_oring + 0.1 * jnp.diag(x_A_flat_cov_oring).min() * jnp.eye(x_A_flat_cov_oring.shape[0])\n",
    "\n",
    "    fixed_atoms = jnp.array(json_data['fixed']['atoms']) - 1\n",
    "    #R0_A = jnp.array(json_data['fixed']['R0_A'])\n",
    "    kval = jnp.float32(json_data['fixed']['kval'])\n",
    "\n",
    "    nconf = x_A.shape[0]\n",
    "\n",
    "    input_size = x_A.shape[1] * 3\n",
    "    hidden_dim = json_data['realNVP']['hidden_dim']\n",
    "    hidden_layers = json_data['realNVP']['hidden_layers']\n",
    "\n",
    "    model = NNflows(input_size=input_size,\n",
    "                     hidden_layers=hidden_layers,\n",
    "                     hidden_dim=hidden_dim)\n",
    "    ener_funs = jax_amber.get_amber_energy_funs(json_data['fname_prmtop'],\n",
    "                                                fixed_atoms[-1],\n",
    "                                                kval)\n",
    "    _, ener_wHO_fun, ener_bond_fun = ener_funs\n",
    "\n",
    "    _, enr_bnd_A0, enr_wHO_A0 = get_energy_values(x_A, ener_funs, R0_A)\n",
    "\n",
    "    _, tenr_bnd_A0, tenr_wHO_A0 = get_energy_values(tx_A, ener_funs, R0_A)\n",
    "\n",
    "    lr = json_data['optax']['learning_rate']\n",
    "    total_steps = json_data['optax']['total_steps']\n",
    "    alpha = json_data['optax']['alpha']\n",
    "    scheduler = optax.cosine_decay_schedule(lr,\n",
    "                                            decay_steps=total_steps,\n",
    "                                            alpha=alpha)\n",
    "\n",
    "    opt_method = optax.chain(\n",
    "        optax.clip(1.0),\n",
    "        optax.adam(learning_rate=scheduler)\n",
    "    )\n",
    "\n",
    "    state = train_state.TrainState.create(\n",
    "        apply_fn=model.apply,\n",
    "        params=model.init(rng, x_A)['params'],\n",
    "        tx=opt_method\n",
    "    )\n",
    "\n",
    "    fixed_R0 = (R0_A)\n",
    "\n",
    "    loss_hist = []\n",
    "    loss_oring_hist = []\n",
    "    loss_oring_f_hist = []\n",
    "    loss_f_hist = []\n",
    "    loss_b_hist = []\n",
    "    loss_oring_b_hist = []\n",
    "\n",
    "    tm_A_hist = []\n",
    "    m_A_hist = []\n",
    "    tm_B_hist = []\n",
    "\n",
    "    switch_gear = []\n",
    "    iterations = 0\n",
    "\n",
    "    state_hist_full = []\n",
    "\n",
    "    for multip in jnp.arange(30):\n",
    "        switch_gear.append(iterations)\n",
    "\n",
    "        factor = 5 * (0.9 ** multip)\n",
    "        \n",
    "        #factor = 1\n",
    "        # if multip == 8:\n",
    "        # factor = 1\n",
    "\n",
    "        #if multip == 11:\n",
    "            #factor = 1\n",
    "        # factor = 1\n",
    "\n",
    "        print(factor)\n",
    "\n",
    "        x_B_flat = jax.random.multivariate_normal(x_key, x_A_flat_mean, x_A_flat_cov / factor, (x_A.shape[0],),\n",
    "                                                  method='svd')\n",
    "        tx_B_flat = jax.random.multivariate_normal(tx_key, x_A_flat_mean, x_A_flat_cov / factor, (tx_A.shape[0],),\n",
    "                                                   method='svd')\n",
    "        # x_B_flat = jax.random.multivariate_normal(x_key, x_A_flat_mean, jnp.eye(x_A_flat_mean.shape[0]) / factor, [x_A.shape[0]])\n",
    "        # tx_B_flat = jax.random.multivariate_normal(tx_key, x_A_flat_mean, jnp.eye(x_A_flat_mean.shape[0]) / factor, [x_A.shape[0]])\n",
    "\n",
    "        x_B = x_B_flat.reshape(x_A.shape)\n",
    "        tx_B = tx_B_flat.reshape(tx_A.shape)\n",
    "\n",
    "        def get_gaussian_energy(x):\n",
    "            x_flat = x.reshape([x.shape[0], x.shape[1] * x.shape[2]])\n",
    "\n",
    "            enr_gaus = -logpdf(x_flat, x_A_flat_mean, x_A_flat_cov / factor)\n",
    "\n",
    "            return enr_gaus\n",
    "\n",
    "        enr_B0 = get_gaussian_energy(x_B)\n",
    "        tenr_B0 = get_gaussian_energy(tx_B)\n",
    "\n",
    "        ener_ref0 = \\\n",
    "            (enr_wHO_A0, enr_B0, enr_bnd_A0)\n",
    "\n",
    "        tener_ref0 = \\\n",
    "            (tenr_wHO_A0, tenr_B0, tenr_bnd_A0)\n",
    "\n",
    "        def loss_value(ener_wHO_fn, ener_bond_fn, enr0_wHO, m_B, log_J_F, m_A, log_J_R, fixed_R0):\n",
    "            enr_wHO_A0, enr_B0, _ = enr0_wHO\n",
    "            R0_A = fixed_R0\n",
    "\n",
    "            enr_A = jax.vmap(ener_wHO_fn, in_axes=(0, None))(m_A, R0_A)\n",
    "\n",
    "            # m_B_flat = m_B.reshape([m_B.shape[0], m_B.shape[1] * m_B.shape[2]])\n",
    "            # enr_B = logpdf(m_B_flat, mean=mean, cov=cov)\n",
    "            enr_B = get_gaussian_energy(m_B)\n",
    "\n",
    "            # enr_bnd_A = jax.vmap(ener_bond_fn) (m_A)\n",
    "\n",
    "            loss_F = beta * (enr_B - enr_wHO_A0) - log_J_F\n",
    "            loss_R = beta * (enr_A - enr_B0) - log_J_R\n",
    "\n",
    "            loss = loss_F.mean() + loss_R.mean()\n",
    "\n",
    "            return loss, loss_F, loss_R\n",
    "\n",
    "        @jax.jit\n",
    "        def train_step(state, inputs, ener_wHO_ref0, fixed_R0):\n",
    "            def loss_fn(params, apply_fn):\n",
    "                x_A, x_B = inputs\n",
    "\n",
    "                m_B, log_J_F = apply_fn({'params': params}, x_A, reverse=True)\n",
    "                m_A, log_J_R = apply_fn({'params': params}, x_B)\n",
    "\n",
    "                loss, loss_f, loss_b = loss_value(ener_wHO_fun, ener_bond_fun, ener_wHO_ref0,\n",
    "                                        m_B, log_J_F, m_A, log_J_R, fixed_R0)\n",
    "\n",
    "                return loss_b.mean()\n",
    "\n",
    "            grads = jax.grad(loss_fn)(state.params, state.apply_fn)\n",
    "\n",
    "            return state.apply_gradients(grads=grads)\n",
    "\n",
    "        state_hist = []\n",
    "        for epoch in range(50000):\n",
    "\n",
    "            iterations += 1\n",
    "            # for ist0 in range(0, nconf, 200):\n",
    "            #    ied0 = ist0 + 200\n",
    "            #    ied0 = jnp.where(ied0 < nconf, ied0, nconf)\n",
    "            #    batch = (x_A[ist0:ied0], x_B[ist0:ied0])\n",
    "            #    ener_wHO_ref0 = (enr_wHO_A0[ist0:ied0], enr_B0[ist0:ied0],\n",
    "            #                     enr_bnd_A0)\n",
    "\n",
    "            #    state = train_step(state, batch, ener_wHO_ref0, fixed_R0)\n",
    "            #rng, x_key= jax.random.split(rng, num=2)\n",
    "            #choice = jax.random.choice(x_key, 8000, shape = [500])\n",
    "            #batch = (x_A[choice], x_B[choice])\n",
    "            \n",
    "            #ener_wHO_ref0 = (enr_wHO_A0[choice], enr_B0[choice],\n",
    "            #                     enr_bnd_A0)\n",
    "            batch = (x_A, x_B)\n",
    "            ener_wHO_ref0 = (enr_wHO_A0, enr_B0, enr_bnd_A0)\n",
    "            state = train_step(state, batch, ener_wHO_ref0, fixed_R0)\n",
    "\n",
    "            if (epoch) % 500 == 0:\n",
    "                #state_hist.append(state.params)\n",
    "\n",
    "                tm_B, tlog_J_F = state.apply_fn({'params': state.params}, tx_A, reverse=True)\n",
    "\n",
    "                tm_A, tlog_J_R = state.apply_fn({'params': state.params}, tx_B)\n",
    "\n",
    "                loss, loss_f, loss_b = loss_value(ener_wHO_fun, ener_bond_fun, tener_ref0,\n",
    "                                                  tm_B, tlog_J_F, tm_A, tlog_J_R, fixed_R0)\n",
    "                \n",
    "\n",
    "                loss_hist.append(loss.item())\n",
    "                loss_f_hist.append(loss_f.mean().item())\n",
    "                loss_b_hist.append(loss_b.mean().item())\n",
    "                \n",
    "                with open('my_results/'+result, 'a') as file:\n",
    "                    file.write('factor: ' + str(factor) + ' epoch: '+ str(epoch) + '\\n loss: ' + str(loss) + '\\n')\n",
    "                    file.write('forward: '+ str(loss_f.mean()) + ' backward: ' + str(loss_b.mean()) + '\\n')\n",
    "\n",
    "                m_B, log_J_F = state.apply_fn({'params': state.params}, x_A, reverse=True)\n",
    "\n",
    "                m_A, log_J_R = state.apply_fn({'params': state.params}, x_B)\n",
    "                \n",
    "                if epoch>2000:\n",
    "                \n",
    "                    last5 = loss_hist[-5:-1]\n",
    "                    last5_2 = loss_hist[-4:]\n",
    "\n",
    "                    last5_b = loss_b_hist[-5:-1]\n",
    "                    last5_b_2 = loss_b_hist[-4:]\n",
    "                    \n",
    "                    last5_f = loss_f_hist[-5:-1]\n",
    "                    last5_f_2 = loss_f_hist[-4:]\n",
    "                    \n",
    "                    if loss_hist[-1] >= 10000:\n",
    "                        state = state.replace (params=test_ckpt['params'],opt_state=test_ckpt['opt_state'])\n",
    "\n",
    "                        break\n",
    "                        \n",
    "                    if loss_f_hist[-1] >= 10000:\n",
    "                        state = state.replace (params=test_ckpt['params'],opt_state=test_ckpt['opt_state'])\n",
    "                        break\n",
    "                        \n",
    "                    if loss_b_hist[-1] >= 10000:\n",
    "                        state = state.replace (params=test_ckpt['params'],opt_state=test_ckpt['opt_state'])\n",
    "                        break\n",
    "\n",
    "                    if (np.mean(last5_f) + 2*np.abs(np.mean(last5_f))) <= np.mean(last5_f_2):\n",
    "\n",
    "                        break\n",
    "\n",
    "                    if epoch > 4000:\n",
    "\n",
    "                        if np.mean(last5) <= np.mean(last5_2):\n",
    "                            if np.mean(last5_b) <= np.mean(last5_b_2):\n",
    "                                break\n",
    "                                \n",
    "                test_ckpt = {'params': state.params, \n",
    "                            'opt_state':state.opt_state}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                        \n",
    "                #if epoch%1000 == 0:\n",
    "                    #print(epoch, loss)\n",
    "        state_hist.append(state.params)\n",
    "        state_hist_full.append(state_hist)\n",
    "\n",
    "\n",
    "    return state_hist_full, [x_A_flat_mean, x_A_flat_cov]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18145b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_addon = 'h,d,n=128,3,3,lesslr,seb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06e12daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_json = 'F18_20_align/input_test.json'\n",
    "\n",
    "with open(fname_json) as f:\n",
    "    json_data = json.load(f)\n",
    "\n",
    "fout = open(json_data['fname_log'], 'w', 1)\n",
    "\n",
    "R0_A = jnp.array(json_data['fixed']['R0_A'])\n",
    "R0_B = jnp.array(json_data['fixed']['R0_B'])\n",
    "\n",
    "rng = jax.random.PRNGKey(0)\n",
    "rng, x_key, tx_key = jax.random.split(rng, num=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d59d1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n",
      "4.5\n",
      "4.050000000000001\n",
      "3.6450000000000005\n",
      "3.280500000000001\n",
      "2.9524500000000007\n",
      "2.6572050000000007\n",
      "2.3914845000000007\n",
      "2.1523360500000006\n",
      "1.9371024450000007\n",
      "1.7433922005000007\n",
      "1.5690529804500009\n",
      "1.4121476824050008\n",
      "1.270932914164501\n",
      "1.1438396227480507\n",
      "1.0294556604732457\n",
      "0.9265100944259212\n",
      "0.8338590849833292\n",
      "0.7504731764849961\n",
      "0.6754258588364968\n",
      "0.607883272952847\n",
      "0.5470949456575623\n",
      "0.4923854510918062\n",
      "0.4431469059826255\n",
      "0.398832215384363\n",
      "0.3589489938459267\n",
      "0.3230540944613341\n",
      "0.2907486850152007\n",
      "0.26167381651368066\n",
      "0.2355064348623126\n"
     ]
    }
   ],
   "source": [
    "x_A, tx_A = get_trajectory(json_data['fname_prmtop'],\n",
    "                              json_data['fname_dcd_A'],\n",
    "                              8000)\n",
    "\n",
    "state_A, parm_A = main_f(x_A, tx_A, R0_A, f'fA{title_addon}.txt')\n",
    "\n",
    "\n",
    "with open(f'my_results/fA{title_addon}.pkl', 'wb') as file:\n",
    "      \n",
    "    # A new file will be created\n",
    "    pickle.dump([state_A, parm_A], file)\n",
    "    \n",
    "del state_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a320960f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n",
      "4.5\n",
      "4.050000000000001\n",
      "3.6450000000000005\n",
      "3.280500000000001\n",
      "2.9524500000000007\n",
      "2.6572050000000007\n",
      "2.3914845000000007\n",
      "2.1523360500000006\n",
      "1.9371024450000007\n",
      "1.7433922005000007\n",
      "1.5690529804500009\n",
      "1.4121476824050008\n",
      "1.270932914164501\n",
      "1.1438396227480507\n",
      "1.0294556604732457\n",
      "0.9265100944259212\n",
      "0.8338590849833292\n",
      "0.7504731764849961\n",
      "0.6754258588364968\n",
      "0.607883272952847\n",
      "0.5470949456575623\n",
      "0.4923854510918062\n",
      "0.4431469059826255\n",
      "0.398832215384363\n",
      "0.3589489938459267\n",
      "0.3230540944613341\n",
      "0.2907486850152007\n",
      "0.26167381651368066\n",
      "0.2355064348623126\n"
     ]
    }
   ],
   "source": [
    "state_A, parm_A = main_b(x_A, tx_A, R0_A, f'bA{title_addon}.txt')\n",
    "\n",
    "\n",
    "with open(f'my_results/bA{title_addon}.pkl', 'wb') as file:\n",
    "      \n",
    "    # A new file will be created\n",
    "    pickle.dump([state_A, parm_A], file)\n",
    "    \n",
    "del state_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32b203c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n",
      "4.5\n",
      "4.050000000000001\n",
      "3.6450000000000005\n",
      "3.280500000000001\n",
      "2.9524500000000007\n",
      "2.6572050000000007\n",
      "2.3914845000000007\n",
      "2.1523360500000006\n",
      "1.9371024450000007\n",
      "1.7433922005000007\n",
      "1.5690529804500009\n",
      "1.4121476824050008\n",
      "1.270932914164501\n",
      "1.1438396227480507\n",
      "1.0294556604732457\n",
      "0.9265100944259212\n",
      "0.8338590849833292\n",
      "0.7504731764849961\n",
      "0.6754258588364968\n",
      "0.607883272952847\n",
      "0.5470949456575623\n",
      "0.4923854510918062\n",
      "0.4431469059826255\n",
      "0.398832215384363\n",
      "0.3589489938459267\n",
      "0.3230540944613341\n",
      "0.2907486850152007\n",
      "0.26167381651368066\n",
      "0.2355064348623126\n"
     ]
    }
   ],
   "source": [
    "x_B, tx_B = get_trajectory(json_data['fname_prmtop'],\n",
    "                              json_data['fname_dcd_B'],\n",
    "                              8000)\n",
    "\n",
    "state_B, parm_B = main_f(x_B, tx_B, R0_B, f'fB{title_addon}.txt')\n",
    "    \n",
    "    \n",
    "with open(f'my_results/fB{title_addon}.pkl', 'wb') as file:\n",
    "    pickle.dump([state_B, parm_B], file)\n",
    "    \n",
    "del state_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0d1a98c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n",
      "4.5\n",
      "4.050000000000001\n",
      "3.6450000000000005\n",
      "3.280500000000001\n",
      "2.9524500000000007\n",
      "2.6572050000000007\n",
      "2.3914845000000007\n",
      "2.1523360500000006\n",
      "1.9371024450000007\n",
      "1.7433922005000007\n",
      "1.5690529804500009\n",
      "1.4121476824050008\n",
      "1.270932914164501\n",
      "1.1438396227480507\n",
      "1.0294556604732457\n",
      "0.9265100944259212\n",
      "0.8338590849833292\n",
      "0.7504731764849961\n",
      "0.6754258588364968\n",
      "0.607883272952847\n",
      "0.5470949456575623\n",
      "0.4923854510918062\n",
      "0.4431469059826255\n",
      "0.398832215384363\n",
      "0.3589489938459267\n",
      "0.3230540944613341\n",
      "0.2907486850152007\n",
      "0.26167381651368066\n",
      "0.2355064348623126\n"
     ]
    }
   ],
   "source": [
    "state_B, parm_B = main_b(x_B, tx_B, R0_B, f'bB{title_addon}.txt')\n",
    "    \n",
    "    \n",
    "with open(f'my_results/bB{title_addon}.pkl', 'wb') as file:\n",
    "    pickle.dump([state_B, parm_B], file)\n",
    "    \n",
    "del state_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e82791f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
